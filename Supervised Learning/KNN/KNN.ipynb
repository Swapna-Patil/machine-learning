{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Link for downloading dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/\n",
    "df = pd.read_csv('iris.data.txt', header = None, names = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setosa = df[df['class'] == 'Iris-setosa']\n",
    "versicolor = df[df['class'] == 'Iris-versicolor']\n",
    "virginica = df[df['class'] == 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(setosa['sepal_length'], setosa['sepal_width'], 'ro', label = 'setosa')\n",
    "plt.plot(versicolor['sepal_length'], versicolor['sepal_width'], 'bo', label = 'versicolor')\n",
    "plt.plot(virginica['sepal_length'], virginica['sepal_width'], 'go', label = 'virginica')\n",
    "plt.xlabel('sepal_length')\n",
    "plt.ylabel('sepal_width')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(setosa['petal_length'], setosa['petal_width'], 'ro', label = 'setosa')\n",
    "plt.plot(versicolor['petal_length'], versicolor['petal_width'], 'bo', label = 'versicolor')\n",
    "plt.plot(virginica['petal_length'], virginica['petal_width'], 'go', label = 'virginica')\n",
    "plt.xlabel('petal_length')\n",
    "plt.ylabel('petal_width')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of setosa: %d' %(len(setosa)))\n",
    "print('length of versicolor: %d' %(len(versicolor)))\n",
    "print('length of virginica: %d' %(len(virginica)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = df[df['is_train'] == True], df[df['is_train'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of train dataset: %d' %(len(train)))\n",
    "print('length of test dataset: %d' %(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train[train.columns[:len(train.columns) - 2]]\n",
    "train_y = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test[test.columns[:len(test.columns) - 2]]\n",
    "test_y = test['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The function 'euclidean_distance' takes\n",
    "**data1** : first data point <br>\n",
    "**data2** : second data point <br>\n",
    "## It returns\n",
    "**euclidean distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(data1, data2):\n",
    "    distance = 0\n",
    "    for i in range(data2.shape[0]):\n",
    "        distance += np.square(data1[i] - data2[i])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The function 'manhattan_distance' takes\n",
    "**data1** : first data point <br>\n",
    "**data2** : second data point <br>\n",
    "## It returns\n",
    "**manhattan_distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manhattan_distance(data1, data2):\n",
    "    distance = 0\n",
    "    for i in range(data2.shape[0]):\n",
    "        distance += abs(data2[i] - data1[i])\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The function 'knn' takes \n",
    "**train_x** : training samples, <br>\n",
    "**train_y** : corresponding labels, <br>\n",
    "**dis_func** : a function which calculates distance <br>\n",
    "**sample** : one test sample <br>\n",
    "**k** : number of training example to look for deciding the class of the given sample. <br>\n",
    "\n",
    "## It returns \n",
    "**cl** : class of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(train_x, train_y, dis_func, sample, k):\n",
    "    distances = {}\n",
    "    \n",
    "    for i in range(len(train_x)):\n",
    "        d = dis_func(sample, train_x.iloc[i])\n",
    "        distances[i] = d\n",
    "    \n",
    "    sorted_dist = sorted(distances.items(), key = lambda x : (x[1], x[0]))\n",
    "    \n",
    "    # take k nearest neighbors\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(sorted_dist[i][0])\n",
    "    \n",
    "    # convert indices into classes\n",
    "    classes = [train_y.iloc[c] for c in neighbors]\n",
    "    \n",
    "    # count each classes in top k\n",
    "    counts = Counter(classes)\n",
    "    \n",
    "    # take vote of max number of samples of a class\n",
    "    list_values = list(counts.values())\n",
    "    list_keys = list(counts.keys())\n",
    "    cl = list_keys[list_values.index(max(list_values))]\n",
    "    \n",
    "    return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl = knn(train_x, train_y, manhattan_distance, test_x.iloc[3], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(test_x, test_y, train_x, train_y, k):\n",
    "    correct = 0\n",
    "    for i in range(len(test_x)):\n",
    "        sample = test_x.iloc[i]\n",
    "        true_label = test_y.iloc[i]\n",
    "        predicted_label_euclidean = knn(train_x, train_y, euclidean_distance, sample, k)\n",
    "        if predicted_label_euclidean == true_label:\n",
    "            correct += 1\n",
    "        \n",
    "    accuracy_euclidean = (correct / len(test_x)) * 100\n",
    "    \n",
    "    correct = 0    # reset correct value to 0\n",
    "    for i in range(len(test_x)):\n",
    "        sample = test_x.iloc[i]\n",
    "        true_label = test_y.iloc[i]\n",
    "        predicted_label_manhattan = knn(train_x, train_y, manhattan_distance, sample, k)\n",
    "        if predicted_label_manhattan == true_label:\n",
    "            correct += 1\n",
    "    accuracy_manhatten = (correct / len(test_x)) * 100\n",
    "    \n",
    "    print(\"model accuracy with euclidean is %0.2f\" %(accuracy_euclidean))\n",
    "    print(\"model accuracy with manhattan is %0.2f\" %(accuracy_manhatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(test_x, test_y, train_x, train_y, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
